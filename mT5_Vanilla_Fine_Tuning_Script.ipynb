{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/upriser72/Bridges-Distribution-Gap-in-Language-Model-Fine-Tuning/blob/main/mT5_Vanilla_Fine_Tuning_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade transformers datasets pandas torch sentencepiece accelerate"
      ],
      "metadata": {
        "id": "n9AT2Icg-tiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    MT5ForConditionalGeneration,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the fine-tuning process.\n",
        "    \"\"\"\n",
        "    # --- 1. Load and Prepare the Dataset ---\n",
        "    # Load the dataset from the CSV file.\n",
        "    # Using engine='python' to handle potential parsing errors in large CSV files.\n",
        "    # on_bad_lines='skip' will skip rows that have formatting issues.\n",
        "    try:\n",
        "        df = pd.read_csv(\"healthcare_dataset.csv\", engine='python', on_bad_lines='skip')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: 'healthcare_dataset.csv' not found.\")\n",
        "        print(\"Please make sure the dataset file is uploaded to your Colab environment and the name matches exactly.\")\n",
        "        return\n",
        "\n",
        "    # Convert the pandas DataFrame to a Hugging Face Dataset\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "\n",
        "    # --- 2. Load Tokenizer and Model ---\n",
        "    model_name = \"google/mt5-small\"\n",
        "    # The tokenizer is responsible for converting text into a format the model can understand.\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    # The model is the pre-trained mT5-small architecture.\n",
        "    model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # --- 3. Preprocess the Data ---\n",
        "    # We need to format the input and output correctly for the T5 model.\n",
        "    # The model will be trained to generate the 'output' from the 'input' column.\n",
        "    prefix = \"diagnose: \"\n",
        "    max_input_length = 512\n",
        "    max_target_length = 256\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        \"\"\"Tokenizes the dataset.\"\"\"\n",
        "        # Create the combined input text for each item in the batch\n",
        "        inputs = [prefix + str(inp) for inp in examples[\"input\"]]\n",
        "\n",
        "        # Tokenize the inputs\n",
        "        model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
        "\n",
        "        # Tokenize the targets (outputs)\n",
        "        # The 'with tokenizer.as_target_tokenizer():' block is essential for T5-style models.\n",
        "        with tokenizer.as_target_tokenizer():\n",
        "            labels = tokenizer(examples[\"output\"], max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
        "\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    # Apply the preprocessing function to the entire dataset\n",
        "    tokenized_dataset = dataset.map(\n",
        "        preprocess_function,\n",
        "        batched=True,\n",
        "    )\n",
        "\n",
        "    # --- 4. Set Up Training ---\n",
        "    # Define training arguments. These control various aspects of the training process.\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=\"./results_mt5_medical\",    # Directory to save the model and results\n",
        "        num_train_epochs=50,                   # Total number of training epochs (increase for better performance on small datasets)\n",
        "        per_device_train_batch_size=2,         # Batch size per device during training\n",
        "        per_device_eval_batch_size=2,          # Batch size for evaluation (if used)\n",
        "        warmup_steps=50,                       # Number of warmup steps for learning rate scheduler\n",
        "        weight_decay=0.01,                     # Strength of weight decay\n",
        "        logging_dir='./logs',                  # Directory for storing logs\n",
        "        logging_steps=10,\n",
        "        save_total_limit=2,                    # Only keep the last 2 saved models\n",
        "        predict_with_generate=True,            # Whether to use generate to calculate generative metrics\n",
        "        report_to=\"none\",                      # Disable integration with Weights & Biases\n",
        "    )\n",
        "\n",
        "    # Data collator prepares batches of data for the model.\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "    # The Trainer class handles the training and evaluation loop.\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    # --- 5. Start Fine-Tuning ---\n",
        "    print(\"Starting the fine-tuning process...\")\n",
        "    trainer.train()\n",
        "    print(\"Fine-tuning complete.\")\n",
        "\n",
        "    # --- 6. Save the Fine-Tuned Model ---\n",
        "    final_model_path = \"./fine_tuned_mt5_medical\"\n",
        "    trainer.save_model(final_model_path)\n",
        "    tokenizer.save_pretrained(final_model_path)\n",
        "    print(f\"Model saved to {final_model_path}\")\n",
        "\n",
        "    # --- 7. Inference Example ---\n",
        "    print(\"\\n--- Running Inference with the Fine-Tuned Model ---\")\n",
        "\n",
        "    # Load the fine-tuned model and tokenizer\n",
        "    trained_model = MT5ForConditionalGeneration.from_pretrained(final_model_path)\n",
        "    trained_tokenizer = AutoTokenizer.from_pretrained(final_model_path)\n",
        "\n",
        "    # Define a new patient query\n",
        "    patient_input = \"I have a persistent dry cough for the last 3 days and a slight fever. I feel tired and have a mild headache. What could this be?\"\n",
        "\n",
        "    # Prepare the input for the model\n",
        "    prompt = f\"diagnose: {patient_input}\"\n",
        "    inputs = trained_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    # Generate the output\n",
        "    print(\"Generating diagnosis...\")\n",
        "    outputs = trained_model.generate(\n",
        "        inputs,\n",
        "        max_length=200,\n",
        "        num_beams=5,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode and print the result\n",
        "    generated_text = trained_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(\"\\nPatient Query:\")\n",
        "    print(patient_input)\n",
        "    print(\"\\nGenerated Medical Advice:\")\n",
        "    print(generated_text)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/112165 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e59682b5af5746f5ba24b0e8bcb75a91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-892899370.py:86: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the fine-tuning process...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='2804150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [    501/2804150 02:28 < 231:48:12, 3.36 it/s, Epoch 0.01/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>37.705500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>38.243500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>34.302800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>34.662800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>33.503100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>32.513100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>29.491300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>29.870600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>26.416700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>27.780800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>23.180400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>27.776100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>27.560400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>21.662300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>23.794600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>21.534300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>21.752800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>21.566000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>20.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>21.522100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>19.978700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>18.674100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>18.384000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>16.484300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>16.093000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>15.188900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>14.117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>14.744400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>14.187000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>13.066600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>13.292500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>12.943600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>12.744000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>11.671200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>11.737300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>10.976200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>11.401800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>10.504000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>11.656100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>9.847800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>10.464800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>9.403700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>9.191100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>8.820100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>8.725900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>8.561100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>9.819500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>7.577900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>7.419400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e59682b5af5746f5ba24b0e8bcb75a91",
            "d7a29c73ff3a4e9fad57fb779ac9eaf2",
            "015de6e9f4a24781b7d3f63cc88150f3",
            "b4ac23ad7a2a4080a7f9bb3573288900",
            "5240be9a2d204aae86a90d2024a63c9f",
            "059eefa123df4f5381aa2effcda5e424",
            "6f25c6d696be418cac2b0996a840192d",
            "f8ffa803bec94b43ac271cc4508f3b4a",
            "00f520d9343b40e6990e1a3496e830e0",
            "02ff630b2e9e47cd9f27a8c993a81681",
            "8cf00e5aa1d04315a910e69697fad3c9"
          ]
        },
        "id": "PWPqpSaS-TVM",
        "outputId": "9938cf88-50dc-4280-bd08-ef4b1c3990d4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e59682b5af5746f5ba24b0e8bcb75a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7a29c73ff3a4e9fad57fb779ac9eaf2",
              "IPY_MODEL_015de6e9f4a24781b7d3f63cc88150f3",
              "IPY_MODEL_b4ac23ad7a2a4080a7f9bb3573288900"
            ],
            "layout": "IPY_MODEL_5240be9a2d204aae86a90d2024a63c9f"
          }
        },
        "d7a29c73ff3a4e9fad57fb779ac9eaf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_059eefa123df4f5381aa2effcda5e424",
            "placeholder": "​",
            "style": "IPY_MODEL_6f25c6d696be418cac2b0996a840192d",
            "value": "Map: 100%"
          }
        },
        "015de6e9f4a24781b7d3f63cc88150f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ffa803bec94b43ac271cc4508f3b4a",
            "max": 112165,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00f520d9343b40e6990e1a3496e830e0",
            "value": 112165
          }
        },
        "b4ac23ad7a2a4080a7f9bb3573288900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ff630b2e9e47cd9f27a8c993a81681",
            "placeholder": "​",
            "style": "IPY_MODEL_8cf00e5aa1d04315a910e69697fad3c9",
            "value": " 112165/112165 [01:46&lt;00:00, 897.18 examples/s]"
          }
        },
        "5240be9a2d204aae86a90d2024a63c9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059eefa123df4f5381aa2effcda5e424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f25c6d696be418cac2b0996a840192d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ffa803bec94b43ac271cc4508f3b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00f520d9343b40e6990e1a3496e830e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02ff630b2e9e47cd9f27a8c993a81681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf00e5aa1d04315a910e69697fad3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}