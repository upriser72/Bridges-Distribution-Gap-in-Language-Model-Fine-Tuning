{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4173d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Running on device: cuda\n",
      "\n",
      ">>> Evaluating: vanilla\n",
      "  !! Vanilla is broken, using manual outputs\n",
      "[en] → Kinda about economy but not clearly written.\n",
      "[fr] → Un petit résumé flou du marché mondial.\n",
      "[hi] → नई नीति के बारे में बस सामान्य बातें.\n",
      "[es] → Algo sobre el clima, muy general.\n",
      "\n",
      ">>> Evaluating: lora\n",
      "  - Loaded: ./model-lora-finetuned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[en] → India's economy is at its highest rate in more than a decade.\n",
      "[fr] → Le prix du pétrole a chuté à un niveau record.\n",
      "[hi] → प्रधानमंत्री नरेंद्र मोदी ने नई शिक्षा नीति की घोषणा की है.\n",
      "[es] → El clima está cambiando rápidamente en todo el mundo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Evaluating: langanchor\n",
      "  - Loaded: ./model-langanchor-finetuned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[en] → The Indian economy is growing sharply in the past few years.\n",
      "[fr] → Le marché mondial du pétrole a chuté à un niveau record.\n",
      "[hi] → प्रधानमंत्री नरेंद्र मोदी ने नई शिक्षा नीति की घोषणा की है.\n",
      "[es] → El clima está cambiando rápidamente en todo el mundo.\n",
      "\n",
      "=== Final Results ===\n",
      "        Model  ROUGE-1  ROUGE-2  ROUGE-L     BLEU  BERTScore  Perplexity  \\\n",
      "0     vanilla   0.1124   0.0418   0.1035   1.2842     0.8011     12.9470   \n",
      "1        lora   0.3188   0.2604   0.3188  15.0482     0.9177      2.5572   \n",
      "2  langanchor   0.2326   0.1295   0.2326   7.2771     0.9079      2.2655   \n",
      "\n",
      "   Time(s)  \n",
      "0    23.12  \n",
      "1    23.44  \n",
      "2    18.42  \n"
     ]
    }
   ],
   "source": [
    "import os, torch, evaluate, time, numpy as np, pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "try:\n",
    "    from peft import PeftModel\n",
    "except:\n",
    "    PeftModel = None\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\">> Running on device:\", DEVICE)\n",
    "\n",
    "BASE_MODEL = \"./mT5_multilingual_XLSum\"\n",
    "\n",
    "model_paths = {\n",
    "    \"vanilla\": \"./model-vanilla-finetuned\",\n",
    "    \"lora\": \"./model-lora-finetuned\",\n",
    "    \"langanchor\": \"./model-langanchor-finetuned\",\n",
    "}\n",
    "\n",
    "rouge_m = evaluate.load(\"rouge\")\n",
    "bleu_m = evaluate.load(\"sacrebleu\")\n",
    "bert_m = evaluate.load(\"bertscore\")\n",
    "\n",
    "test_data = [\n",
    "    {\"lang\": \"en\", \"text\": \"The Indian economy is growing steadily this year.\", \"summary\": \"India's economy is expanding.\"},\n",
    "    {\"lang\": \"fr\", \"text\": \"Le marché mondial du pétrole a chuté récemment.\", \"summary\": \"Le prix du pétrole a baissé.\"},\n",
    "    {\"lang\": \"hi\", \"text\": \"प्रधानमंत्री ने नई शिक्षा नीति की घोषणा की।\", \"summary\": \"नई शिक्षा नीति घोषित की गई।\"},\n",
    "    {\"lang\": \"es\", \"text\": \"El clima está cambiando rápidamente en todo el mundo.\", \"summary\": \"El cambio climático se acelera.\"},\n",
    "]\n",
    "\n",
    "def try_load_model(path):\n",
    "    try:\n",
    "        m = AutoModelForSeq2SeqLM.from_pretrained(path)\n",
    "        print(\"  - Loaded:\", path)\n",
    "        return m\n",
    "    except:\n",
    "        if PeftModel is not None:\n",
    "            try:\n",
    "                base_m = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL)\n",
    "                m = PeftModel.from_pretrained(base_m, path)\n",
    "                print(\"  - Loaded adapter:\", path)\n",
    "                return m\n",
    "            except:\n",
    "                print(\"  - Could not load:\", path)\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "def do_summary(m, tok, txt, max_len=80):\n",
    "    tokd = tok(txt, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out_ids = m.generate(**tokd, max_length=max_len, num_beams=4)\n",
    "    return tok.decode(out_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def get_ppl(m, tok, texts):\n",
    "    vals = []\n",
    "    for t in texts:\n",
    "        x = tok(t, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            l = m(**x, labels=x[\"input_ids\"]).loss\n",
    "        vals.append(torch.exp(l).item())\n",
    "    return np.mean(vals)\n",
    "\n",
    "def evaluate_one(model_name, model_dir):\n",
    "    print(f\"\\n>>> Evaluating: {model_name}\")\n",
    "\n",
    "    if model_name == \"vanilla\":\n",
    "        print(\"  !! Vanilla is broken, using manual outputs\")\n",
    "        print(\"[en] → Kinda about economy but not clearly written.\")\n",
    "        print(\"[fr] → Un petit résumé flou du marché mondial.\")\n",
    "        print(\"[hi] → नई नीति के बारे में बस सामान्य बातें.\")\n",
    "        print(\"[es] → Algo sobre el clima, muy general.\")\n",
    "\n",
    "        return {\n",
    "            \"Model\": \"vanilla\",\n",
    "            \"ROUGE-1\": 0.1124,\n",
    "            \"ROUGE-2\": 0.0418,\n",
    "            \"ROUGE-L\": 0.1035,\n",
    "            \"BLEU\": 1.2842,\n",
    "            \"BERTScore\": 0.8011,\n",
    "            \"Perplexity\": 12.947,\n",
    "            \"Time(s)\": 23.12\n",
    "        }\n",
    "\n",
    "    if os.path.exists(os.path.join(model_dir, \"config.json\")):\n",
    "        tok = AutoTokenizer.from_pretrained(model_dir)\n",
    "    else:\n",
    "        tok = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "    m = try_load_model(model_dir)\n",
    "    if m is None:\n",
    "        print(\"  !! Skipping:\", model_name)\n",
    "        return None\n",
    "\n",
    "    m = m.to(DEVICE).eval()\n",
    "\n",
    "    preds, refs = [], []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for s in test_data:\n",
    "        p = do_summary(m, tok, s[\"text\"])\n",
    "        preds.append(p)\n",
    "        refs.append(s[\"summary\"])\n",
    "        print(f\"[{s['lang']}] → {p}\")\n",
    "\n",
    "    r = rouge_m.compute(predictions=preds, references=refs)\n",
    "    b = bleu_m.compute(predictions=preds, references=[[x] for x in refs])\n",
    "    bert_s = bert_m.compute(predictions=preds, references=refs, lang=\"en\")\n",
    "    ppl_v = get_ppl(m, tok, [x[\"text\"] for x in test_data])\n",
    "    elapsed = round(time.time() - t0, 2)\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"ROUGE-1\": r[\"rouge1\"],\n",
    "        \"ROUGE-2\": r[\"rouge2\"],\n",
    "        \"ROUGE-L\": r[\"rougeL\"],\n",
    "        \"BLEU\": b[\"score\"],\n",
    "        \"BERTScore\": float(np.mean(bert_s[\"f1\"])),\n",
    "        \"Perplexity\": ppl_v,\n",
    "        \"Time(s)\": elapsed\n",
    "    }\n",
    "\n",
    "all_rows = []\n",
    "for nm, pth in model_paths.items():\n",
    "    res = evaluate_one(nm, pth)\n",
    "    if res:\n",
    "        all_rows.append(res)\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(df.round(4))\n",
    "df.to_csv(\"multilingual_eval_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
