{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-kw592jl9Bo",
        "outputId": "14d892a5-fef1-44d5-cdcb-ba72ae36fd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "en→hi\n",
            "Input: The weather is good today.\n",
            "Predicted: आज मौसम अच्छा है।\n",
            "Expected:  आज मौसम अच्छा है\n",
            "BLEU: 1.0000\n",
            "\n",
            "en→hi\n",
            "Input: I am reading a book.\n",
            "Predicted: मैं एक किताब पढ़ रहा हूं।\n",
            "Expected:  मैं किताब पढ़ रहा हूँ\n",
            "BLEU: 0.0000\n",
            "\n",
            "en→mr\n",
            "Input: The weather is good today.\n",
            "Predicted: आज मौसम चांगला आहे.\n",
            "Expected:  आज हवामान छान आहे\n",
            "BLEU: 0.0000\n",
            "\n",
            "en→mr\n",
            "Input: I am reading a book.\n",
            "Predicted: मी एक पुस्तक वाचतो.\n",
            "Expected:  मी पुस्तक वाचत आहे\n",
            "BLEU: 0.0000\n",
            "\n",
            "hi→en\n",
            "Input: मैं स्कूल जा रहा हूँ\n",
            "Predicted: I am going to school.\n",
            "Expected:  I am going to school\n",
            "BLEU: 1.0000\n",
            "\n",
            "hi→en\n",
            "Input: आज बहुत गर्मी है\n",
            "Predicted: It is very hot today.\n",
            "Expected:  It is very hot today\n",
            "BLEU: 1.0000\n",
            "\n",
            "mr→en\n",
            "Input: मी पाणी पित आहे\n",
            "Predicted: I am drinking water.\n",
            "Expected:  I am drinking water\n",
            "BLEU: 1.0000\n",
            "\n",
            "mr→en\n",
            "Input: आज हवामान छान आहे\n",
            "Predicted: The weather is today.\n",
            "Expected:  The weather is nice today\n",
            "BLEU: 0.0000\n",
            "\n",
            "hi→mr\n",
            "Input: मैं बाजार जा रहा हूँ\n",
            "Predicted: मी बाजार जातो.\n",
            "Expected:  मी बाजारात जात आहे\n",
            "BLEU: 0.0000\n",
            "\n",
            "hi→mr\n",
            "Input: मैं पानी पी रहा हूँ\n",
            "Predicted: मी पाणी पीत आहे.\n",
            "Expected:  मी पाणी पित आहे\n",
            "BLEU: 0.0000\n",
            "\n",
            "mr→hi\n",
            "Input: मी घरी जात आहे\n",
            "Predicted: मैं घर जा रहा हूँ।\n",
            "Expected:  मैं घर जा रहा हूँ\n",
            "BLEU: 1.0000\n",
            "\n",
            "mr→hi\n",
            "Input: मी पुस्तक वाचत आहे\n",
            "Predicted: मैं किताब पढ़ रहा हूँ।\n",
            "Expected:  मैं किताब पढ़ रहा हूँ\n",
            "BLEU: 1.0000\n",
            "\n",
            "=== AVERAGE BLEU SCORES PER LANGUAGE PAIR ===\n",
            "en→hi      : 0.5000\n",
            "en→mr      : 0.0000\n",
            "hi→en      : 1.0000\n",
            "mr→en      : 0.5000\n",
            "hi→mr      : 0.0000\n",
            "mr→hi      : 1.0000\n",
            "\n",
            "Overall Average BLEU: 0.5000\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import evaluate\n",
        "import torch\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load m2m100 multilingual model\n",
        "model_name = \"facebook/m2m100_418M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "# Load standard BLEU (not SacreBLEU)\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "# Helper: normalize text for fair comparison\n",
        "def normalize_text(text):\n",
        "    text = text.strip()\n",
        "    text = re.sub(r\"[।\\.\\,\\!\\?]\", \"\", text)  # remove punctuation\n",
        "    text = re.sub(r\"\\s+\", \" \", text)         # normalize spaces\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Define dataset with all pairs\n",
        "data = [\n",
        "    # English → Hindi\n",
        "    {\"src_lang\": \"en\", \"tgt_lang\": \"hi\", \"input\": \"The weather is good today.\", \"expected\": \"आज मौसम अच्छा है\"},\n",
        "    {\"src_lang\": \"en\", \"tgt_lang\": \"hi\", \"input\": \"I am reading a book.\", \"expected\": \"मैं किताब पढ़ रहा हूँ\"},\n",
        "\n",
        "    # English → Marathi\n",
        "    {\"src_lang\": \"en\", \"tgt_lang\": \"mr\", \"input\": \"The weather is good today.\", \"expected\": \"आज हवामान छान आहे\"},\n",
        "    {\"src_lang\": \"en\", \"tgt_lang\": \"mr\", \"input\": \"I am reading a book.\", \"expected\": \"मी पुस्तक वाचत आहे\"},\n",
        "\n",
        "    # Hindi → English\n",
        "    {\"src_lang\": \"hi\", \"tgt_lang\": \"en\", \"input\": \"मैं स्कूल जा रहा हूँ\", \"expected\": \"I am going to school\"},\n",
        "    {\"src_lang\": \"hi\", \"tgt_lang\": \"en\", \"input\": \"आज बहुत गर्मी है\", \"expected\": \"It is very hot today\"},\n",
        "\n",
        "    # Marathi → English\n",
        "    {\"src_lang\": \"mr\", \"tgt_lang\": \"en\", \"input\": \"मी पाणी पित आहे\", \"expected\": \"I am drinking water\"},\n",
        "    {\"src_lang\": \"mr\", \"tgt_lang\": \"en\", \"input\": \"आज हवामान छान आहे\", \"expected\": \"The weather is nice today\"},\n",
        "\n",
        "    # Hindi → Marathi\n",
        "    {\"src_lang\": \"hi\", \"tgt_lang\": \"mr\", \"input\": \"मैं बाजार जा रहा हूँ\", \"expected\": \"मी बाजारात जात आहे\"},\n",
        "    {\"src_lang\": \"hi\", \"tgt_lang\": \"mr\", \"input\": \"मैं पानी पी रहा हूँ\", \"expected\": \"मी पाणी पित आहे\"},\n",
        "\n",
        "    # Marathi → Hindi\n",
        "    {\"src_lang\": \"mr\", \"tgt_lang\": \"hi\", \"input\": \"मी घरी जात आहे\", \"expected\": \"मैं घर जा रहा हूँ\"},\n",
        "    {\"src_lang\": \"mr\", \"tgt_lang\": \"hi\", \"input\": \"मी पुस्तक वाचत आहे\", \"expected\": \"मैं किताब पढ़ रहा हूँ\"},\n",
        "]\n",
        "\n",
        "# Group BLEU scores by language pair\n",
        "lang_pair_scores = defaultdict(list)\n",
        "\n",
        "def translate(sample):\n",
        "    src, src_lang, tgt_lang = sample[\"input\"], sample[\"src_lang\"], sample[\"tgt_lang\"]\n",
        "    tokenizer.src_lang = src_lang\n",
        "    tokenizer.tgt_lang = tgt_lang\n",
        "    inputs = tokenizer(src, return_tensors=\"pt\", padding=True).to(device)\n",
        "    forced_token_id = tokenizer.get_lang_id(tgt_lang)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, forced_bos_token_id=forced_token_id, max_length=50)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Evaluate per language pair\n",
        "for sample in data:\n",
        "    pred = translate(sample)\n",
        "    ref = sample[\"expected\"]\n",
        "    pair = f\"{sample['src_lang']}→{sample['tgt_lang']}\"\n",
        "\n",
        "    pred_norm = normalize_text(pred)\n",
        "    ref_norm = normalize_text(ref)\n",
        "\n",
        "    # Compute BLEU for each example individually\n",
        "    # predictions should be list of strings, references should be list of list of strings\n",
        "    bleu_score = bleu.compute(predictions=[pred_norm], references=[[ref_norm]])[\"bleu\"]\n",
        "    lang_pair_scores[pair].append(bleu_score)\n",
        "\n",
        "    print(f\"\\n{pair}\")\n",
        "    print(f\"Input: {sample['input']}\")\n",
        "    print(f\"Predicted: {pred}\")\n",
        "    print(f\"Expected:  {ref}\")\n",
        "    print(f\"BLEU: {bleu_score:.4f}\")\n",
        "\n",
        "# Compute average BLEU per pair\n",
        "print(\"\\n=== AVERAGE BLEU SCORES PER LANGUAGE PAIR ===\")\n",
        "for pair, scores in lang_pair_scores.items():\n",
        "    avg = sum(scores) / len(scores)\n",
        "    print(f\"{pair:10s} : {avg:.4f}\")\n",
        "\n",
        "# Overall average\n",
        "overall = sum(sum(v) / len(v) for v in lang_pair_scores.values()) / len(lang_pair_scores)\n",
        "print(f\"\\nOverall Average BLEU: {overall:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
